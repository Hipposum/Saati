# Сжатие изображений с использованием SVD и рандомизированного SVD

## Описание проекта

Этот проект демонстрирует применение алгоритмов сингулярного разложения (SVD) и рандомизированного SVD (RSVD) для сжатия изображений. Проект включает полную реализацию обоих алгоритмов с подробными комментариями и анализом результатов.

## Структура проекта

```
Saati/
├── image_svd_compression.ipynb  # Основной Jupyter notebook с реализацией
├── saati.ipynb                  # Предыдущий проект (метод Саати)
├── README.md                    # Основной README репозитория
└── README_SVD.md               # Этот файл
```

## Требования

Для запуска проекта необходимы следующие библиотеки Python:

```python
numpy>=1.19.0
matplotlib>=3.3.0
PIL (Pillow)>=8.0.0
```

Установка зависимостей:

```bash
pip install numpy matplotlib pillow
```

## Использование

### 1. Подготовка изображения

Поместите изображение `picture.jpg` в корневую директорию проекта. Если файл не найден, notebook автоматически создаст тестовое изображение.

### 2. Запуск notebook

```bash
jupyter notebook image_svd_compression.ipynb
```

или откройте notebook в Google Colab / JupyterLab.

### 3. Выполнение ячеек

Выполните все ячейки последовательно. Notebook автоматически:
- Загрузит и обработает изображение
- Выполнит SVD разложение
- Построит графики анализа
- Сравнит алгоритмы SVD и RSVD
- Сохранит результаты в PNG файлы

## Содержание notebook

### 1. Загрузка и подготовка данных
- Загрузка изображения
- Конвертация в градации серого
- Нормализация данных

### 2. Классический алгоритм SVD
- Реализация SVD через собственные значения и векторы
- Без использования встроенной функции `np.linalg.svd`
- Подробные комментарии к каждому шагу

### 3. Анализ сингулярных значений
- График сингулярных значений
- Логарифмическая шкала
- Накопленная энергия

### 4. Оценка качества сжатия
- Метрика PSNR (Peak Signal-to-Noise Ratio)
- Относительная ошибка Фробениуса
- Визуализация сжатых изображений для k = 50, 100, 500, 1000

### 5. Рандомизированный SVD (RSVD)
- Реализация RSVD с параметрами p и q
- Сравнение с классическим SVD
- Анализ точности и скорости

### 6. Исследование параметров RSVD
- Влияние параметра p (oversampling)
- Влияние параметра q (степенные итерации)
- Графики зависимостей

### 7. Сравнение производительности
- Время выполнения для различных значений k
- График ускорения
- Итоговая таблица сравнения

## Ключевые формулы

### SVD разложение
```
A = U Σ V^T
```

где:
- `U` - матрица левых сингулярных векторов (m×m)
- `Σ` - диагональная матрица сингулярных значений (m×n)
- `V^T` - транспонированная матрица правых сингулярных векторов (n×n)

### Приближение ранга k
```
A_k = U_k Σ_k V_k^T
```

### PSNR (Peak Signal-to-Noise Ratio)
```
PSNR = 20 × log10(MAX_PIXEL / √MSE)
```

### Относительная ошибка
```
err = ||A - A_k|| / ||A||
```

## Результаты

Notebook генерирует следующие файлы с результатами:

1. **svd_compression_comparison.png** - Визуализация сжатых изображений (классический SVD)
2. **svd_metrics.png** - Графики PSNR и относительной ошибки
3. **rsvd_compression_comparison.png** - Визуализация сжатых изображений (RSVD)
4. **svd_vs_rsvd_comparison.png** - Сравнение SVD и RSVD
5. **rsvd_parameters_analysis.png** - Анализ влияния параметров p и q
6. **timing_comparison.png** - Сравнение времени выполнения

## Основные выводы

1. **Классический SVD**:
   - Точное разложение матрицы
   - Высокие вычислительные затраты
   - Подходит для малых матриц

2. **Рандомизированный SVD**:
   - Хорошее приближение с меньшими затратами
   - Значительное ускорение для больших k
   - Оптимальные параметры: p=5-10, q=1-2

3. **Сжатие изображений**:
   - k=100-200 достаточно для хорошего качества
   - PSNR > 30 dB считается приемлемым
   - Экспоненциальное убывание ошибки с ростом k

## Теоретическая справка

### Алгоритм классического SVD

1. Вычислить A^T × A
2. Найти собственные значения и векторы A^T × A → V и σ²
3. Вычислить A × A^T
4. Найти собственные значения и векторы A × A^T → U
5. Отсортировать по убыванию σ

### Алгоритм RSVD

1. Сгенерировать случайную матрицу Ω (n × (k+p))
2. Вычислить Y = A × Ω
3. Применить степенные итерации: Y = (AA^T)^q × Y
4. QR разложение: Y = QR
5. Вычислить B = Q^T × A
6. SVD малой матрицы: B = Ũ Σ Ṽ^T
7. Получить U = Q × Ũ

## Литература и ссылки

1. Halko, N., Martinsson, P. G., & Tropp, J. A. (2011). Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions. SIAM review, 53(2), 217-288.

2. Golub, G. H., & Van Loan, C. F. (2013). Matrix computations (4th ed.). Johns Hopkins University Press.

3. Trefethen, L. N., & Bau III, D. (1997). Numerical linear algebra (Vol. 50). SIAM.

## Автор

[Ваше ФИО]
[Номер группы]
[Вариант]

## Лицензия

Этот проект создан в образовательных целях.
